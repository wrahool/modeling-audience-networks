m2$lrt
1 - pchisq(m1$lrt - m2$lrt, m1$df - m2$df)
1 - pchisq(13.66076 - 0.4275453, 1)
m1$lrt - m2$lrt
#df:
m1$df - m2$df
#p-value:
1 - pchisq(m1$lrt - m2$lrt, m1$df - m2$df)
6.138655-2.030219
1-pchisq(6.138655-2.030219,5-4
)
1 - pchisq(m1$lrt, m1$df)
1 - pchisq(m2$lrt, m2$df)
#3.6
m2 = loglin(lalive.tab, list(c(1,2,3), c(1,3,4), c(2,3,4)), eps = 0.0001)
#3.6
m2 = loglin(lalive.tab, list(c(1,2,3), c(1,3,4), c(2,3,4)), fit = T, eps = 0.0001)
m2$fit
m2$fit[1,]
m2$fit[1,,]
m2$fit[1,,,]
m2$fit
m2$fit
#L = temp, S = seasonal
56.10212 * 754.10212 / (1209.89788 *  18.89788)
#L = perm, S = seasonal
221.63706 * 2590.63706 / (1140.36294 * 162.36294)
#L = temp, S = other
173.89788 * 1287.89788 / (1831.10212 * 66.10212)
#L = perm, S = other
1423.36294 * 6201.36294 / (3125.63706, 910.63706)
#L = perm, S = other
1423.36294 * 6201.36294 / (3125.63706 * 910.63706)
m2$fit
#L = temp, S = seasonal
56.10212 * 754.10212 / (1209.89788 *  18.89788) #1.85
#L = perm, S = seasonal
221.63706 * 2590.63706 / (1140.36294 * 162.36294) #3.10
#L = temp, S = other
173.89788 * 1287.89788 / (1831.10212 * 66.10212) #1.85
#L = perm, S = other
1423.36294 * 6201.36294 / (3125.63706 * 910.63706) #3.10
m2$fit
#L = temp, S = seasonal, A = after
56.10212 / (56.10212 + 1209.89788)
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212)
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294)
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706)
#5
#L = temp, S = other, A = after
173.89788 / (173.89788 + 1831.10212)
#6
#L = temp, S = other, A = before
66.10212 / (66.10212 + 1287.89788)
#6
#L = temp, S = other, A = before
66.10212 / (66.10212 + 1287.89788) #0.04
#5
#L = temp, S = other, A = after
173.89788 / (173.89788 + 1831.10212)
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706) #0.05
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706) #0.058
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294) #0.1
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294) #0.16
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212) #0.02
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212) #0.024
#1
#L = temp, S = seasonal, A = after
56.10212 / (56.10212 + 1209.89788) #0.04
m2$fit
#7
#L = perm, S = other, A = after
1423.36294 / (1423.36294 + 3125.63706)
#8
#L = perm, S = other, A = before
910.63706 / (910.63706 + 6201.36294)
#8
#L = perm, S = other, A = before
910.63706 / (910.63706 + 6201.36294) #0.12
0.044/0.024
0.16/0.058
0.086 / 0.086
0.31/0.12
0.044/0.024
0.16/0.058
0.086 /0.048
0.31/0.12
o for s = seasonal
#temp: 0.044/0.024
0.044/0.024
0.16/0.058
0.086/0.048
0.31/0.12
load("~/../Google Drive/Annenberg UPenn/8 Spring 2018/STAT 501 - Nonparametric Methods and Log Linear Models/Rst501.RData")
lalive.tab
load("~/../Google Drive/Annenberg UPenn/8 Spring 2018/STAT 501 - Nonparametric Methods and Log Linear Models/Rst501.RData")
lalive.tab
mt = margin.table(lalive.tab, c(2,3,4))
dimnames(mt)
#1.2
loglin(mt, list(1, c(2,3)), eps = 0.0001)
1 - pchisq(920.8895, 3)
pchisq(920.8895, 3)
#1.3
loglin(mt, list(c(1,2), c(1,3), c(2,3)), eps = 0.0001)
dimnames(mt)
1 - pchisq(26.90355, 1)
#1.4
mt
#OR for seasonal
1266*2753/(773*1362) #3.31
#OR for other
2005*7112/(1354*4549) #2.31
dimnames(lalive.tab)
loglin(lalive.tab, list(c(1,3,4),c(2,3,4)), eps = 0.0001)
pchisq(711.9607, 4)
dimnames(lalive.tab)
ft = loglin(lalive.tab, list(c(1,2), c(1,3,4), c(2,3,4)), eps = 0.0001, fit = T)$fit
ft
61.81396*759.81396/(1204.18604 * 13.18604) #2.95
217.66384 * 2586.66384 / (1144.33616 * 166.33616) # 2.95
192.95100 * 1306.95100 / (1812.04900 * 47.04900) #2.95
1402.57120 * 6180.57120 / (3146.42880 * 931.42880) #2.95
#3.2
ft = loglin(lalive.tab, list(c(1,2,4), c(1,3,4), c(2,3,4)), eps = 0.0001, fit = T)$fit
ft
#L = temp, S = seasonal
62.09456 * 760.09456 / (1203.90544 * 12.90544) #3.03
#L = perm, S = seasonal
219.90544 * 2588.90544 / (1142.09456 * 164.09456) #3.03
#L = temp, S = other
192.76041 * 1306.76041 / (1812.23959 * 47.23959) #2.94
#L = perm, S = other
1400.23959 * 6178.23959 / (3148.76041 * 933.76041) #2.94
#look at bulk pg 119; questions 1.4, 2.1, 2.2
m1 = loglin(lalive.tab, list(c(1,2), c(1,3,4), c(2,3,4)), eps = 0.0001)
dimnames(lalive.tab)
#look at bulk pg 119; questions 1.4, 2.1, 2.2
m1 = loglin(lalive.tab, list(c(1,2), c(1,3,4), c(2,3,4)), eps = 0.0001)
m2 = loglin(lalive.tab, list(c(1,2,3), c(1,3,4), c(2,3,4)), eps = 0.0001)
#chi sq:
m1$lrt - m2$lrt #13.23
#df:
m1$df - m2$df #1
#p-value:
1 - pchisq(m1$lrt - m2$lrt, m1$df - m2$df) #0.00027
m1$lrt
m2$lrt
#chi sq:
m1$lrt - m2$lrt #13.23
#df:
m1$df - m2$df #1
m1$df
m2$df
#3.6
m2 = loglin(lalive.tab, list(c(1,2,3), c(1,3,4), c(2,3,4)), fit = T, eps = 0.0001)
m2$fit
#L = temp, S = seasonal
56.10212 * 754.10212 / (1209.89788 *  18.89788) #1.85
#L = perm, S = seasonal
221.63706 * 2590.63706 / (1140.36294 * 162.36294) #3.10
#L = temp, S = other
173.89788 * 1287.89788 / (1831.10212 * 66.10212) #1.85
#L = perm, S = other
1423.36294 * 6201.36294 / (3125.63706 * 910.63706) #3.10
m2
1-pchisq(0.4275453, 2)
#3.7
#1
#L = temp, S = seasonal, A = after
56.10212 / (56.10212 + 1209.89788) #0.044
m2$fit
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212) #0.024
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294) #0.16
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706) #0.058
#5
#L = temp, S = other, A = after
173.89788 / (173.89788 + 1831.10212) #0.086
#6
#L = temp, S = other, A = before
66.10212 / (66.10212 + 1287.89788) #0.048
#7
#L = perm, S = other, A = after
1423.36294 / (1423.36294 + 3125.63706) #0.31
#8
#L = perm, S = other, A = before
910.63706 / (910.63706 + 6201.36294) #0.12
s = seasonal
#temp: 0.044/0.024 = 1.8
#after:before ratio for s = seasonal
#temp: 0.044/0.024 = 1.8
#after:before ratio for s = other
#after:before ratio for s = other
#temp: 0.086/0.048 = 1.79
x <- c(3:6, 9:12, 15:18)
x
rand()
rand
sample(x, 1)
install.packages("mturkr")
install.packages("MTurkR")
install.packages("MTurkR-GUI")
library(MTurkR)
?RegisterHITType
install.packages("ineq")
library(ineq)
version
df = read.csv("../Google Drive/Annenberg UPenn/0 Dissertation Project/02_ComScoreData/01_IndiaData/03_Auxiliary/avg_dc_pr_full.csv", as.is = T)
head(df)
cor.test(df$avg.dc, df$avg.pr)
cor.test(df$avg.dc, df$avg.pr, method = "pearson", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "pearson", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "spearman", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "kendall", continuity = F, conf.level = 0.95)
df = read.csv("../Google Drive/Annenberg UPenn/0 Dissertation Project/02_ComScoreData/01_IndiaData/03_Auxiliary/avg_dc_pr_full.csv", as.is = T)
cor.test(df$avg.dc, df$avg.pr, method = "pearson", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "spearman", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "kendall", continuity = F, conf.level = 0.95)
library(RJSONIO)
tweetscores::posterior_samples
tweetscores::posterior_samples$alpha
tweetscores::posterior_samples$gamma
class(tweetscores::posterior_samples$gamma)
class(tweetscores::posterior_samples$alpha)
dim(tweetscores::posterior_samples$alpha)
tweetscores::posterior_samples$alpha[1,]
library(tweetscores)
sd(8, 10, 11, 12, 14)
stdev(8, 10, 11, 12, 14)
sd(c(8, 10, 11, 12, 14))
boxplot(c(8, 10, 11, 12, 14))
p = 0.51
sum = 0
for(i in 51:100) {
sum = sum + (p^i)*((1-p)^(100-i))
}
sum
p = 0.51
sum = 0
for(i in 51:100) {
sum = sum + ((p^i)*((1-p)^(100-i)))
}
sum
i = 51
p = 0.51
P^i
p^i
(p^51)*((1-p)^49)
?choose
p = 0.51
sum = 0
for(i in 51:100) {
sum = sum + (choose(100, i)*(p^i)*((1-p)^(100-i)))
}
sum
choose(5, 1)
p = 0.51
sum = 0
for(i in 501:1000) {
sum = sum + (choose(100, i)*(p^i)*((1-p)^(100-i)))
}
print(sum)
p = 0.51
sum = 0
for(i in 501:1000) {
sum = sum + (choose(1000, i)*(p^i)*((1-p)^(100-i)))
}
print(sum)
p = 0.51
sum = 0
for(i in 501:1000) {
sum = sum + (choose(1000, i)*(p^i)*((1-p)^(1000-i)))
}
print(sum)
p = 0.51
sum = 0
for(i in 501:10000) {
sum = sum + (choose(10000, i)*(p^i)*((1-p)^(10000-i)))
}
print(sum)
version()
version
library(stringr)
str_locate_all(x, "ATAT")
x = "XYZATATATXYZ"
str_locate_all(x, "ATAT")
str_locate_all(x, "(?=ATAT)")
str_locate_all(x, "[AT]")
str_locate_all(x, "[ATAT]")
x = c(0,0,0,0,0,0,0,0,1,1)
table(x)
sample(x, 1)
s = sample(x, 50, replace = T)
s
mu = mean(s)
mu
x = c(0,0,0,0,0,0,0,0,1,1)
trials = 10
mus = NULL
for(i in 1:trials) {
s = sample(x, 50, replace = T)
mu = mean(s)
mus = c(mus, mu)
}
mus
plot(density(mus))
temp = function(n)
x = c(0,0,0,0,0,0,0,0,1,1)
trials = 10
mus = NULL
for(i in 1:n) {
s = sample(x, 50, replace = T)
mu = mean(s)
mus = c(mus, mu)
}
plot(density(mus))
}
temp = function(n){
x = c(0,0,0,0,0,0,0,0,1,1)
trials = 10
mus = NULL
for(i in 1:n) {
s = sample(x, 50, replace = T)
mu = mean(s)
mus = c(mus, mu)
}
plot(density(mus))
}
temp = function(n){
x = c(0,0,0,0,0,0,0,0,1,1)
trials = 10
mus = NULL
for(i in 1:n) {
s = sample(x, 50, replace = T)
mu = mean(s)
mus = c(mus, mu)
}
plot(density(mus))
}
temp(10)
temp(5)
temp(5)
temp(5)
temp(5)
temp(10)
temp(20)
temp(30)
temp(50)
temp(100)
temp(1000)
temp(10000)
temp(100000)
temp(100)
temp(1000)
temp(10000)
temp(51000)
library(ggplot2)
library(tidyverse)
install.packages('tidyr')
library(tidyr)
tidyr::pivot_wider
library(tidyverse)
library(igraph)
setwd("C:/Users/Subhayan/Documents/Work/modeling-audience-networks/")
##################################################
# model paramters
# n1: number of websites in the universe
# n2: number of members of the audiences
# n3: number of websites each person visits
# n4: number ot types of websites / people
# alpha: measure of randomness
# each person visits a total of n3 websites
# which websites they visit depends on a tuning parameter alpha (which controls their randomness)
# when alpha is 0 they can only visit websites whose outlet_id == their own p_id
# when alpha is 1 they can visit any website
# when alpha is 0.5, half of the websites they visit can be any website, the other half have to be restricted to those whose outlet_id == p_id
##################################################
get_simulated_network <- function(n1, n2, n3, n4, alpha, use_unique = TRUE) {
outlet_ids <- 1:n1
p_ids <- 1:n2
types <- LETTERS[1:n4]
outlets_tbl <- tibble(
outlet_id = outlet_ids,
outlet_name = paste("O", outlet_ids, sep = "_"),
outlet_type = rep(types, each = n1/n4)
)
audience_tbl <- tibble(
p_id = p_ids,
p_name = paste("P", p_ids, sep = ""),
p_type = rep(types, each = n2/n4)
)
audience_el <- NULL
# loop over each person
for(p in 1:1000) {
# print(p)
# when alpha is 0 all of their choices are selective
# when alpha is 1 all of their choices are random
random_choices_allowed <- round(alpha * n3)
selective_choices_allowed <- round(n3 - random_choices_allowed)
selective_chosen_outlets <- outlets_tbl %>%               # only from
filter(outlet_type == audience_tbl$p_type[p]) %>%       # those outlets where outlet_type == p_type
pull(outlet_id) %>%                                     #
sample(selective_choices_allowed, replace = TRUE)       # sample the number of selective outlets allowed
random_chosen_outlets <- outlets_tbl %>%                  # from
pull(outlet_id) %>%                                     # all outlets in the universe
sample(random_choices_allowed, replace = TRUE)          # sample the number of random outlets allowed
all_chosen_outlets <- c(selective_chosen_outlets,
random_chosen_outlets)
if (use_unique == TRUE)
all_chosen_outlets <- unique(all_chosen_outlets)
# build the edge-list for the audience network
audience_el <- audience_el %>%
rbind(
tibble(
p_name = paste("P", rep(p, length(all_chosen_outlets)), sep = "_"),             # one column is the p_id
outlet_name = paste("O", all_chosen_outlets, sep = "_") # second column is the outlet_id
)
)
}
outlet_reach <- audience_el %>%
pull(outlet_name) %>%
table() %>%
as_tibble() %>%
rename(uv = n) %>%
select(outlet_name = 1, everything())
audience_g <- graph_from_data_frame(audience_el, directed = F)
V(audience_g)$type <- substr(V(audience_g)$name, 1, 1) == "O"
projection_graphs <- bipartite_projection(audience_g, multiplicity = TRUE)
outlet_projection <- projection_graphs$proj2
V(outlet_projection)$type <- V(outlet_projection)$name %>%
lapply(FUN = function(x) {
outlets_tbl %>%
filter(outlet_name == x) %>%
pull(outlet_type)
}
) %>%
unlist()
# colrs <- c("gray50", "tomato", "gold", "purple", "cyan")
V(outlet_projection)$color <- ifelse(V(outlet_projection)$type == "A", "gray50",
ifelse(V(outlet_projection)$type == "B", "tomato",
ifelse(V(outlet_projection)$type == "C", "gold",
ifelse(V(outlet_projection)$type == "D", "olivedrab4",
"cyan"))))
outlet_projection_sl <- outlet_projection
outlet_projection_sl[from=V(outlet_projection_sl), to=V(outlet_projection_sl)] = 1
for(v in V(outlet_projection_sl)$name) {
E(outlet_projection_sl)[v %--% v]$weight <- outlet_reach %>%
filter(outlet_name == v) %>%
pull(uv)
}
return(outlet_projection_sl)
}
n1 <- 500 # number of websites in the universe
n2 <- 1000 # number of members of the audiences
n3 <- 100 # number of websites each person visits
n4 <- 5 # number ot types of websites / people
# each person visits a total of n3 websites
# which websites they visit depends on a tuning parameter alpha (which controls their randomness)
# when alpha is 0 they can only visit websites whose outlet_id == their own p_id
# when alpha is 1 they can visit any website
# when alpha is 0.5, half of the websites they visit can be any website, the other half have to be restricted to those whose outlet_id == p_id
set.seed(42)
simulation_tbl <- NULL
for(i in 1:50) {
count <- 1
for(alpha in seq(0.5, 1, by = 0.01)) {
message(alpha)
g_sl <- get_simulated_network(n1, n2, n3, n4, alpha, use_unique = TRUE)
g <- simplify(g_sl, remove.loops = TRUE)
simulation_tbl <- tibble(alpha = alpha,
n_comm_sl = length(walktrap.community(g_sl)),
n_comm = length(walktrap.community(g))
) %>% rbind(simulation_tbl)
if(count %% 10 == 0) {
write_csv(simulation_tbl, paste0("data/", i, "_master_simulation_results", count, ".csv"))
simulation_tbl <- NULL
}
count <- count + 1
}
}
# write_csv(simulation_tbl, "data/simulation_results5to8.csv")
# temp <- simulation_tbl %>%
#   filter(!n_comm  %in% c(500),
#          !n_comm_sl %in% c(500))
#
# ggplot(simulation_tbl) +
#   geom_line(aes(x=alpha, y=n_comm_sl), color = "red") +
#   geom_line(aes(x=alpha, y=n_comm), color = "blue")
